{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data. Below is the first 5 rows of the data. The column 'behavior' can have 4 value {'pv','fav','cart','buy'} corresponding for 4 actions visit, favour, add to cart and buy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  category_id behavior   timestamp\n",
      "0        1  2268318      2520377       pv  1511544070\n",
      "1        1  2333346      2520771       pv  1511561733\n",
      "2        1  2576651       149192       pv  1511572885\n",
      "3        1  3830808      4181361       pv  1511593493\n",
      "4        1  4365585      2520377       pv  1511596146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>1.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.124134e+05</td>\n",
       "      <td>2.578439e+06</td>\n",
       "      <td>2.706415e+06</td>\n",
       "      <td>1.511962e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.727758e+05</td>\n",
       "      <td>1.487995e+06</td>\n",
       "      <td>1.464783e+06</td>\n",
       "      <td>2.293642e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.830000e+02</td>\n",
       "      <td>2.171000e+03</td>\n",
       "      <td>1.505118e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000723e+06</td>\n",
       "      <td>1.295192e+06</td>\n",
       "      <td>1.331853e+06</td>\n",
       "      <td>1.511768e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.001908e+06</td>\n",
       "      <td>2.577764e+06</td>\n",
       "      <td>2.733371e+06</td>\n",
       "      <td>1.511965e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.003157e+06</td>\n",
       "      <td>3.864858e+06</td>\n",
       "      <td>4.145813e+06</td>\n",
       "      <td>1.512175e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.004381e+06</td>\n",
       "      <td>5.163001e+06</td>\n",
       "      <td>5.158474e+06</td>\n",
       "      <td>1.512317e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id       item_id   category_id     timestamp\n",
       "count  1.000000e+05  1.000000e+05  1.000000e+05  1.000000e+05\n",
       "mean   9.124134e+05  2.578439e+06  2.706415e+06  1.511962e+09\n",
       "std    2.727758e+05  1.487995e+06  1.464783e+06  2.293642e+05\n",
       "min    1.000000e+00  2.830000e+02  2.171000e+03  1.505118e+09\n",
       "25%    1.000723e+06  1.295192e+06  1.331853e+06  1.511768e+09\n",
       "50%    1.001908e+06  2.577764e+06  2.733371e+06  1.511965e+09\n",
       "75%    1.003157e+06  3.864858e+06  4.145813e+06  1.512175e+09\n",
       "max    1.004381e+06  5.163001e+06  5.158474e+06  1.512317e+09"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"UserBehavior.csv\",dtype={'user_id':int, 'item_id':int, 'category_id':int, 'behavior':str, 'timestamp':np.int64})\n",
    "print(ratings.head())\n",
    "ratings.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate percentage of each behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pv      89.709\n",
      "cart     5.446\n",
      "fav      2.744\n",
      "buy      2.101\n",
      "Name: behavior, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "behavior_counts = ratings['behavior'].value_counts()\n",
    "behavior_percents = behavior_counts / len(ratings) * 100\n",
    "print(behavior_percents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encode each type of behavior to a specific real number in  [0;1] and store the score in column 'score'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>behavior</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2268318</td>\n",
       "      <td>2520377</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511544070</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2333346</td>\n",
       "      <td>2520771</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511561733</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2576651</td>\n",
       "      <td>149192</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511572885</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3830808</td>\n",
       "      <td>4181361</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511593493</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4365585</td>\n",
       "      <td>2520377</td>\n",
       "      <td>pv</td>\n",
       "      <td>1511596146</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  category_id behavior   timestamp  score\n",
       "0        1  2268318      2520377       pv  1511544070   0.02\n",
       "1        1  2333346      2520771       pv  1511561733   0.02\n",
       "2        1  2576651       149192       pv  1511572885   0.02\n",
       "3        1  3830808      4181361       pv  1511593493   0.02\n",
       "4        1  4365585      2520377       pv  1511596146   0.02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert behavior types to scores\n",
    "behavior_scores = {'pv': 0.02, 'fav': 0.5, 'cart': 0.3, 'buy': 0.9}\n",
    "ratings['score'] = ratings['behavior'].map(behavior_scores)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>79715</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>230380</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>266784</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>271696</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>568695</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>818610</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>929177</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1305059</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1323189</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1338525</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1340922</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1531036</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2028434</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2041056</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2087357</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2104483</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2266567</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2268318</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2278603</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2286574</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2333346</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2576651</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2734026</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2791761</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2951368</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3108797</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>3157558</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3219016</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3239041</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>3682069</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>3745169</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>3827899</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>3830808</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>3911125</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>4092065</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>4152983</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>4170517</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>4198227</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>4365585</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  score\n",
       "1         1    79715   0.02\n",
       "2         1   230380   0.02\n",
       "3         1   266784   0.04\n",
       "4         1   271696   0.02\n",
       "5         1   568695   0.02\n",
       "6         1   818610   0.02\n",
       "7         1   929177   0.02\n",
       "8         1  1305059   0.02\n",
       "9         1  1323189   0.02\n",
       "10        1  1338525   0.02\n",
       "11        1  1340922   0.02\n",
       "12        1  1531036   0.02\n",
       "13        1  2028434   0.02\n",
       "14        1  2041056   0.02\n",
       "15        1  2087357   0.04\n",
       "16        1  2104483   0.02\n",
       "17        1  2266567   0.02\n",
       "18        1  2268318   0.02\n",
       "19        1  2278603   0.02\n",
       "20        1  2286574   0.02\n",
       "21        1  2333346   0.02\n",
       "22        1  2576651   0.02\n",
       "23        1  2734026   0.02\n",
       "24        1  2791761   0.02\n",
       "25        1  2951368   0.02\n",
       "26        1  3108797   0.02\n",
       "27        1  3157558   0.02\n",
       "28        1  3219016   0.04\n",
       "29        1  3239041   0.04\n",
       "30        1  3682069   0.02\n",
       "31        1  3745169   0.02\n",
       "32        1  3827899   0.02\n",
       "33        1  3830808   0.02\n",
       "34        1  3911125   0.02\n",
       "35        1  4092065   0.02\n",
       "36        1  4152983   0.02\n",
       "37        1  4170517   0.04\n",
       "38        1  4198227   0.02\n",
       "39        1  4365585   0.02"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings.groupby(['user_id', 'item_id'])['score'].sum().reset_index()\n",
    "ratings[1:40]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a mapping from real user_id and item_id to consecutive_user_id and consecutive_item_id (1....num users/items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>consecutive_user_id</th>\n",
       "      <th>consecutive_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>46259</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>79715</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>230380</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>266784</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>271696</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75719</th>\n",
       "      <td>1004381</td>\n",
       "      <td>4835134</td>\n",
       "      <td>0.02</td>\n",
       "      <td>982</td>\n",
       "      <td>2134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75720</th>\n",
       "      <td>1004381</td>\n",
       "      <td>4845368</td>\n",
       "      <td>0.02</td>\n",
       "      <td>982</td>\n",
       "      <td>48705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>1004381</td>\n",
       "      <td>4988513</td>\n",
       "      <td>0.02</td>\n",
       "      <td>982</td>\n",
       "      <td>28819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75722</th>\n",
       "      <td>1004381</td>\n",
       "      <td>4995608</td>\n",
       "      <td>0.02</td>\n",
       "      <td>982</td>\n",
       "      <td>21087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75723</th>\n",
       "      <td>1004381</td>\n",
       "      <td>5048225</td>\n",
       "      <td>0.02</td>\n",
       "      <td>982</td>\n",
       "      <td>64466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75724 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  score  consecutive_user_id  consecutive_item_id\n",
       "0            1    46259   0.04                    0                    0\n",
       "1            1    79715   0.02                    0                    1\n",
       "2            1   230380   0.02                    0                    2\n",
       "3            1   266784   0.04                    0                    3\n",
       "4            1   271696   0.02                    0                    4\n",
       "...        ...      ...    ...                  ...                  ...\n",
       "75719  1004381  4835134   0.02                  982                 2134\n",
       "75720  1004381  4845368   0.02                  982                48705\n",
       "75721  1004381  4988513   0.02                  982                28819\n",
       "75722  1004381  4995608   0.02                  982                21087\n",
       "75723  1004381  5048225   0.02                  982                64466\n",
       "\n",
       "[75724 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#`ratings` is a pandas dataframe with columns 'user_id', 'item_id', and 'score'\n",
    "user_ids = ratings['user_id'].unique()\n",
    "item_ids = ratings['item_id'].unique()\n",
    "\n",
    "# Create a mapping of original IDs to consecutive IDs for users and items\n",
    "user_id_map = pd.Series(np.arange(len(user_ids)), index=user_ids)\n",
    "item_id_map = pd.Series(np.arange(len(item_ids)), index=item_ids)\n",
    "\n",
    "# Map the original user and item IDs to consecutive IDs\n",
    "ratings['consecutive_user_id'] = user_id_map[ratings['user_id']].values\n",
    "ratings['consecutive_item_id'] = item_id_map[ratings['item_id']].values\n",
    "ratings\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create user-item matriuser_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983, 64467)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum up all scores of a user\n",
    "user_scores = ratings.groupby(['consecutive_user_id', 'consecutive_item_id'])['score'].sum()\n",
    "# Create a user-item matrix\n",
    "user_item_matrix = user_scores.unstack()\n",
    "num_users, num_items = user_item_matrix.shape\n",
    "num_users, num_items\n",
    "user_item_matrix\n",
    "user_item_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>consecutive_item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>64457</th>\n",
       "      <th>64458</th>\n",
       "      <th>64459</th>\n",
       "      <th>64460</th>\n",
       "      <th>64461</th>\n",
       "      <th>64462</th>\n",
       "      <th>64463</th>\n",
       "      <th>64464</th>\n",
       "      <th>64465</th>\n",
       "      <th>64466</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consecutive_user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983 rows × 64467 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "consecutive_item_id  0      1      2      3      4      5      6      7      \\\n",
       "consecutive_user_id                                                           \n",
       "0                     0.04   0.02   0.02   0.04   0.02   0.02   0.02   0.02   \n",
       "1                      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2                      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3                      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4                      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...                    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "978                    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "979                    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "980                    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "981                    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "982                    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "consecutive_item_id  8      9      ...  64457  64458  64459  64460  64461  \\\n",
       "consecutive_user_id                ...                                      \n",
       "0                     0.02   0.02  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "1                      NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "2                      NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "3                      NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "4                      NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "...                    ...    ...  ...    ...    ...    ...    ...    ...   \n",
       "978                    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "979                    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "980                    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "981                    NaN    NaN  ...    NaN    NaN    NaN    NaN    NaN   \n",
       "982                    NaN    NaN  ...   0.02   0.04   0.02   0.02   0.02   \n",
       "\n",
       "consecutive_item_id  64462  64463  64464  64465  64466  \n",
       "consecutive_user_id                                     \n",
       "0                      NaN    NaN    NaN    NaN    NaN  \n",
       "1                      NaN    NaN    NaN    NaN    NaN  \n",
       "2                      NaN    NaN    NaN    NaN    NaN  \n",
       "3                      NaN    NaN    NaN    NaN    NaN  \n",
       "4                      NaN    NaN    NaN    NaN    NaN  \n",
       "...                    ...    ...    ...    ...    ...  \n",
       "978                    NaN    NaN    NaN    NaN    NaN  \n",
       "979                    NaN    NaN    NaN    NaN    NaN  \n",
       "980                    NaN    NaN    NaN    NaN    NaN  \n",
       "981                    NaN    NaN    NaN    NaN    NaN  \n",
       "982                   0.02   0.02   0.02   0.02   0.02  \n",
       "\n",
       "[983 rows x 64467 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11949302852922095"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate percentage of non-nan values in user-item matrix\n",
    "num_non_nan = np.count_nonzero(~np.isnan(user_item_matrix))\n",
    "num_non_nan / (num_users * num_items) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>consecutive_item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>64457</th>\n",
       "      <th>64458</th>\n",
       "      <th>64459</th>\n",
       "      <th>64460</th>\n",
       "      <th>64461</th>\n",
       "      <th>64462</th>\n",
       "      <th>64463</th>\n",
       "      <th>64464</th>\n",
       "      <th>64465</th>\n",
       "      <th>64466</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consecutive_user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.608696e-02</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>1.608696e-02</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>-3.913043e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "      <td>-8.326673e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>5.551115e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>6.938894e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>1.173333e-02</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "      <td>-8.266667e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983 rows × 64467 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "consecutive_item_id         0             1             2             3      \\\n",
       "consecutive_user_id                                                           \n",
       "0                    1.608696e-02 -3.913043e-03 -3.913043e-03  1.608696e-02   \n",
       "1                   -8.326673e-17 -8.326673e-17 -8.326673e-17 -8.326673e-17   \n",
       "2                    5.551115e-17  5.551115e-17  5.551115e-17  5.551115e-17   \n",
       "3                    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4                    2.775558e-17  2.775558e-17  2.775558e-17  2.775558e-17   \n",
       "...                           ...           ...           ...           ...   \n",
       "978                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "979                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "980                  6.938894e-18  6.938894e-18  6.938894e-18  6.938894e-18   \n",
       "981                 -1.387779e-17 -1.387779e-17 -1.387779e-17 -1.387779e-17   \n",
       "982                  6.938894e-18  6.938894e-18  6.938894e-18  6.938894e-18   \n",
       "\n",
       "consecutive_item_id         4             5             6             7      \\\n",
       "consecutive_user_id                                                           \n",
       "0                   -3.913043e-03 -3.913043e-03 -3.913043e-03 -3.913043e-03   \n",
       "1                   -8.326673e-17 -8.326673e-17 -8.326673e-17 -8.326673e-17   \n",
       "2                    5.551115e-17  5.551115e-17  5.551115e-17  5.551115e-17   \n",
       "3                    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4                    2.775558e-17  2.775558e-17  2.775558e-17  2.775558e-17   \n",
       "...                           ...           ...           ...           ...   \n",
       "978                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "979                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "980                  6.938894e-18  6.938894e-18  6.938894e-18  6.938894e-18   \n",
       "981                 -1.387779e-17 -1.387779e-17 -1.387779e-17 -1.387779e-17   \n",
       "982                  6.938894e-18  6.938894e-18  6.938894e-18  6.938894e-18   \n",
       "\n",
       "consecutive_item_id         8             9      ...         64457  \\\n",
       "consecutive_user_id                              ...                 \n",
       "0                   -3.913043e-03 -3.913043e-03  ...  3.469447e-18   \n",
       "1                   -8.326673e-17 -8.326673e-17  ... -8.326673e-17   \n",
       "2                    5.551115e-17  5.551115e-17  ...  5.551115e-17   \n",
       "3                    0.000000e+00  0.000000e+00  ...  0.000000e+00   \n",
       "4                    2.775558e-17  2.775558e-17  ...  2.775558e-17   \n",
       "...                           ...           ...  ...           ...   \n",
       "978                  0.000000e+00  0.000000e+00  ...  0.000000e+00   \n",
       "979                  0.000000e+00  0.000000e+00  ...  0.000000e+00   \n",
       "980                  6.938894e-18  6.938894e-18  ...  6.938894e-18   \n",
       "981                 -1.387779e-17 -1.387779e-17  ... -1.387779e-17   \n",
       "982                  6.938894e-18  6.938894e-18  ... -8.266667e-03   \n",
       "\n",
       "consecutive_item_id         64458         64459         64460         64461  \\\n",
       "consecutive_user_id                                                           \n",
       "0                    3.469447e-18  3.469447e-18  3.469447e-18  3.469447e-18   \n",
       "1                   -8.326673e-17 -8.326673e-17 -8.326673e-17 -8.326673e-17   \n",
       "2                    5.551115e-17  5.551115e-17  5.551115e-17  5.551115e-17   \n",
       "3                    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4                    2.775558e-17  2.775558e-17  2.775558e-17  2.775558e-17   \n",
       "...                           ...           ...           ...           ...   \n",
       "978                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "979                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "980                  6.938894e-18  6.938894e-18  6.938894e-18  6.938894e-18   \n",
       "981                 -1.387779e-17 -1.387779e-17 -1.387779e-17 -1.387779e-17   \n",
       "982                  1.173333e-02 -8.266667e-03 -8.266667e-03 -8.266667e-03   \n",
       "\n",
       "consecutive_item_id         64462         64463         64464         64465  \\\n",
       "consecutive_user_id                                                           \n",
       "0                    3.469447e-18  3.469447e-18  3.469447e-18  3.469447e-18   \n",
       "1                   -8.326673e-17 -8.326673e-17 -8.326673e-17 -8.326673e-17   \n",
       "2                    5.551115e-17  5.551115e-17  5.551115e-17  5.551115e-17   \n",
       "3                    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4                    2.775558e-17  2.775558e-17  2.775558e-17  2.775558e-17   \n",
       "...                           ...           ...           ...           ...   \n",
       "978                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "979                  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "980                  6.938894e-18  6.938894e-18  6.938894e-18  6.938894e-18   \n",
       "981                 -1.387779e-17 -1.387779e-17 -1.387779e-17 -1.387779e-17   \n",
       "982                 -8.266667e-03 -8.266667e-03 -8.266667e-03 -8.266667e-03   \n",
       "\n",
       "consecutive_item_id         64466  \n",
       "consecutive_user_id                \n",
       "0                    3.469447e-18  \n",
       "1                   -8.326673e-17  \n",
       "2                    5.551115e-17  \n",
       "3                    0.000000e+00  \n",
       "4                    2.775558e-17  \n",
       "...                           ...  \n",
       "978                  0.000000e+00  \n",
       "979                  0.000000e+00  \n",
       "980                  6.938894e-18  \n",
       "981                 -1.387779e-17  \n",
       "982                 -8.266667e-03  \n",
       "\n",
       "[983 rows x 64467 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy user-item matrix\n",
    "user_item_matrix_copy = user_item_matrix.copy()\n",
    "#fill all nan values with the row's mean\n",
    "user_item_matrix_copy = user_item_matrix_copy.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "#subtract the row's mean from each value\n",
    "user_item_matrix_copy = user_item_matrix_copy.apply(lambda row: row - row.mean(), axis=1)\n",
    "user_item_matrix_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with less than 5 non-zero values: 0\n",
      "Number of columns with less than 5 non-zero values: 0\n"
     ]
    }
   ],
   "source": [
    "#find row and column vector have less than 5 non-zero values\n",
    "row_vector = user_item_matrix_copy.apply(lambda row: np.count_nonzero(row), axis=1)\n",
    "col_vector = user_item_matrix_copy.apply(lambda col: np.count_nonzero(col), axis=0)\n",
    "#print number of rows and columns that have less than 3 non-zero values\n",
    "print('Number of rows with less than 5 non-zero values:', len(row_vector[row_vector < 5]))\n",
    "print('Number of columns with less than 5 non-zero values:', len(col_vector[col_vector <5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_matrix(matrix, test_ratio=0.2):\n",
    "    num_rows, num_cols = matrix.shape\n",
    "    train = np.zeros((num_rows, num_cols))\n",
    "    test = np.zeros((num_rows, num_cols))\n",
    "    for i in range(num_cols):\n",
    "        #find indices of non-zero elements\n",
    "        indices = matrix[:, i].nonzero()[0]\n",
    "        if len(indices) < 3:\n",
    "            continue\n",
    "        test_size = int(len(indices) * test_ratio)\n",
    "        test_idx = np.random.choice(indices, test_size, replace=False)\n",
    "        test[test_idx, i] = matrix[test_idx, i]\n",
    "        train[:, i] = matrix[:, i]\n",
    "        train[test_idx, i] = 0\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rating_sparse_tensor(matrix):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        matrix: A 2D numpy array representing the user-item matrix.\n",
    "        \n",
    "    Returns:\n",
    "        a tf.SparseTensor representing the ratings matrix.\n",
    "    \"\"\"\n",
    "    # Find the indices of the non-zero elements in the matrix\n",
    "    row_indices, col_indices = np.nonzero(matrix)\n",
    "    \n",
    "    # Get the non-zero values in the matrix\n",
    "    values = matrix[row_indices, col_indices]\n",
    "    \n",
    "    # Compute the number of users and items in the matrix\n",
    "    num_users = matrix.shape[0]\n",
    "    num_items = matrix.shape[1]\n",
    "    \n",
    "    # Create a SparseTensorValue object\n",
    "    sparse_tensor_value = tf.SparseTensorValue(\n",
    "        indices=np.array([row_indices, col_indices]).T,\n",
    "        values=values,\n",
    "        dense_shape=[num_users, num_items]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return sparse_tensor_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_root_mean_square_error(r,u,v):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    r: A SparseTensor rating matrix, of dense_shape [N, M]\n",
    "    u: A dense Tensor U such that U_i is the embedding of user i.\n",
    "    v: A dense Tensor V such that V_j is the embedding of item j.\n",
    "  Returns:\n",
    "    A scalar Tensor representing the MSE between the true ratings and the\n",
    "      model's predictions.\n",
    "  \"\"\"\n",
    "  # Compute the predicted tensor\n",
    "  uv = tf.matmul(u, v, transpose_b=True)\n",
    "  \n",
    "  # Get the indices and values of the non-zero elements in r\n",
    "  indices = r.indices\n",
    "  values = r.values\n",
    "  \n",
    "  # Extract the corresponding elements from the predicted tensor\n",
    "  pred_values = tf.gather_nd(uv, indices)\n",
    "  \n",
    "  # Compute the mean squared error of the non-zero elements\n",
    "  mse = tf.reduce_mean(tf.square(values - pred_values))\n",
    "  \n",
    "  # Compute the root mean squared error\n",
    "  rmse = tf.sqrt(mse)\n",
    "  \n",
    "  return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title CFModel helper class (run this cell)\n",
    "class CFModel(object):\n",
    "  \"\"\"Simple class that represents a collaborative filtering model\"\"\"\n",
    "  def __init__(self, embedding_vars, loss, metrics=None):\n",
    "    \"\"\"Initializes a CFModel.\n",
    "    Args:\n",
    "      embedding_vars: A dictionary of tf.Variables.\n",
    "      loss: A float Tensor. The loss to optimize.\n",
    "      metrics: optional list of dictionaries of Tensors. The metrics in each\n",
    "        dictionary will be plotted in a separate figure during training.\n",
    "    \"\"\"\n",
    "    self._embedding_vars = embedding_vars\n",
    "    self._loss = loss\n",
    "    self._metrics = metrics\n",
    "    self._embeddings = {k: None for k in embedding_vars}\n",
    "    self._session = None\n",
    "\n",
    "  @property\n",
    "  def embeddings(self):\n",
    "    \"\"\"The embeddings dictionary.\"\"\"\n",
    "    return self._embeddings\n",
    "\n",
    "  def train(self, num_iterations=30, learning_rate=1.0, plot_results=True,\n",
    "            optimizer=tf.train.AdamOptimizer):\n",
    "    \"\"\"Trains the model.\n",
    "    Args:\n",
    "      iterations: number of iterations to run.\n",
    "      learning_rate: optimizer learning rate.\n",
    "      plot_results: whether to plot the results at the end of training.\n",
    "      optimizer: the optimizer to use. Default to GradientDescentOptimizer.\n",
    "    Returns:\n",
    "      The metrics dictionary evaluated at the last iteration.\n",
    "    \"\"\"\n",
    "    with self._loss.graph.as_default():\n",
    "      opt = optimizer(learning_rate)\n",
    "      train_op = opt.minimize(self._loss)\n",
    "      local_init_op = tf.group(\n",
    "          tf.variables_initializer(opt.variables()),\n",
    "          tf.local_variables_initializer())\n",
    "      if self._session is None:\n",
    "        self._session = tf.Session()\n",
    "        with self._session.as_default():\n",
    "          self._session.run(tf.global_variables_initializer())\n",
    "          self._session.run(tf.tables_initializer())\n",
    "          tf.train.start_queue_runners()\n",
    "\n",
    "    with self._session.as_default():\n",
    "      local_init_op.run()\n",
    "      iterations = []\n",
    "      metrics = self._metrics or ({},)\n",
    "      metrics_vals = [collections.defaultdict(list) for _ in self._metrics]\n",
    "\n",
    "      # Train and append results.\n",
    "      for i in range(num_iterations + 1):\n",
    "        _, results = self._session.run((train_op, metrics))\n",
    "        if (i % 10 == 0) or i == num_iterations:\n",
    "          print(\"\\r iteration %d: \" % i + \", \".join(\n",
    "                [\"%s=%f\" % (k, v) for r in results for k, v in r.items()]),\n",
    "                end='')\n",
    "          iterations.append(i)\n",
    "          for metric_val, result in zip(metrics_vals, results):\n",
    "            for k, v in result.items():\n",
    "              metric_val[k].append(v)\n",
    "\n",
    "      for k, v in self._embedding_vars.items():\n",
    "        self._embeddings[k] = v.eval()\n",
    "\n",
    "      if plot_results:\n",
    "        # Plot the metrics.\n",
    "        num_subplots = len(metrics)+1\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(num_subplots*10, 8)\n",
    "        for i, metric_vals in enumerate(metrics_vals):\n",
    "          ax = fig.add_subplot(1, num_subplots, i+1)\n",
    "          for k, v in metric_vals.items():\n",
    "            ax.plot(iterations, v, label=k)\n",
    "          ax.set_xlim([1, num_iterations])\n",
    "          ax.legend()\n",
    "      return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solution\n",
    "def build_model(train_ratings,test_ratings, embedding_dim=40, init_stddev=1.):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    ratings: a DataFrame of the ratings\n",
    "    embedding_dim: the dimension of the embedding vectors.\n",
    "    init_stddev: float, the standard deviation of the random initial embeddings.\n",
    "  Returns:\n",
    "    model: a CFModel.\n",
    "  \"\"\"\n",
    "  # SparseTensor representation of the train and test datasets.\n",
    "  A_train = build_rating_sparse_tensor(train_ratings)\n",
    "  A_test = build_rating_sparse_tensor(test_ratings)\n",
    "  # Initialize the embeddings using a normal distribution.\n",
    "  U = tf.Variable(tf.random_normal(\n",
    "      [A_train.dense_shape[0], embedding_dim], stddev=init_stddev))\n",
    "  V = tf.Variable(tf.random_normal(\n",
    "      [A_train.dense_shape[1], embedding_dim], stddev=init_stddev))\n",
    "  train_loss = sparse_root_mean_square_error(A_train, U, V)\n",
    "  test_loss = sparse_root_mean_square_error(A_test, U, V)\n",
    "  metrics = {\n",
    "      'train_rmse': train_loss,\n",
    "      'test_rmse': test_loss\n",
    "  }\n",
    "  embeddings = {\n",
    "      \"user_id\": U,\n",
    "      \"item_id\": V\n",
    "  }\n",
    "  return CFModel(embeddings, train_loss, [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravity(U, V):\n",
    "  \"\"\"Creates a gravity loss given two embedding matrices.\"\"\"\n",
    "  return 1. / (U.shape[0]*V.shape[0]) * tf.reduce_sum(\n",
    "      tf.matmul(U, U, transpose_a=True) * tf.matmul(V, V, transpose_a=True))\n",
    "\n",
    "def build_regularized_model(\n",
    "    train_ratings,test_ratings, embedding_dim=30, regularization_coeff=.1, gravity_coeff=1.,\n",
    "    init_stddev=0.1):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    ratings: the DataFrame of ratings.\n",
    "    embedding_dim: The dimension of the embedding space.\n",
    "    regularization_coeff: The regularization coefficient lambda.\n",
    "    gravity_coeff: The gravity regularization coefficient lambda_g.\n",
    "  Returns:\n",
    "    A CFModel object that uses a regularized loss.\n",
    "  \"\"\"\n",
    "  # SparseTensor representation of the train and test datasets.\n",
    "  A_train = build_rating_sparse_tensor(train_ratings)\n",
    "  A_test = build_rating_sparse_tensor(test_ratings)\n",
    "  U = tf.Variable(tf.random_normal(\n",
    "      [A_train.dense_shape[0], embedding_dim], stddev=init_stddev))\n",
    "  V = tf.Variable(tf.random_normal(\n",
    "      [A_train.dense_shape[1], embedding_dim], stddev=init_stddev))\n",
    "\n",
    "  error_train = sparse_root_mean_square_error(A_train, U, V)\n",
    "  error_test = sparse_root_mean_square_error(A_test, U, V)\n",
    "  gravity_loss = gravity_coeff * gravity(U, V)\n",
    "  regularization_loss = regularization_coeff * (\n",
    "      tf.reduce_sum(U*U)/U.shape[0] + tf.reduce_sum(V*V)/V.shape[0])\n",
    "  total_loss = error_train + regularization_loss + gravity_loss\n",
    "  losses = {\n",
    "      'train_rmse_error_observed': error_train,\n",
    "      'test_rmse_error_observed': error_test,\n",
    "  }\n",
    "  loss_components = {\n",
    "      'observed_loss': error_train,\n",
    "      'regularization_loss': regularization_loss,\n",
    "      'gravity_loss': gravity_loss,\n",
    "  }\n",
    "  embeddings = {\"user_id\": U, \"item_id\": V}\n",
    "\n",
    "  return CFModel(embeddings, total_loss, [losses,loss_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.718092204512616e-06\n",
      "3.660021060499416e-05\n",
      "4.6318302809506784e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "train_matrix, test_matrix = split_matrix(user_item_matrix_copy.values)\n",
    "print(mean_squared_error(train_matrix, user_item_matrix_copy.values))\n",
    "print(mean_squared_error(test_matrix, user_item_matrix_copy.values))\n",
    "print(mean_squared_error(train_matrix, test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      " iteration 80: train_rmse=0.005845, test_rmse=0.009987"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_rmse': 0.0058451057, 'test_rmse': 0.009986718}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(train_matrix,test_matrix, embedding_dim=35, init_stddev=0.3)\n",
    "model.train(num_iterations=80, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m reg_model \u001b[39m=\u001b[39m build_regularized_model(train_matrix,test_matrix,regularization_coeff\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, gravity_coeff\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, embedding_dim\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m,init_stddev\u001b[39m=\u001b[39m\u001b[39m.3\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m reg_model\u001b[39m.\u001b[39;49mtrain(num_iterations\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[15], line 43\u001b[0m, in \u001b[0;36mCFModel.train\u001b[1;34m(self, num_iterations, learning_rate, plot_results, optimizer)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mSession()\n\u001b[0;32m     42\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m---> 43\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mrun(tf\u001b[39m.\u001b[39;49mglobal_variables_initializer())\n\u001b[0;32m     44\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mrun(tf\u001b[39m.\u001b[39mtables_initializer())\n\u001b[0;32m     45\u001b[0m   tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mstart_queue_runners()\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extend_graph()\n\u001b[0;32m   1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1401\u001b[0m, in \u001b[0;36mBaseSession._extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extend_graph\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1400\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_session_run_lock():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m     tf_session\u001b[39m.\u001b[39;49mExtendSession(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session)\n",
      "\u001b[1;31mMemoryError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "reg_model = build_regularized_model(train_matrix,test_matrix,regularization_coeff=0.05, gravity_coeff=0.05, embedding_dim=40,init_stddev=.3)\n",
    "reg_model.train(num_iterations=60, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " k = 3, RMSE on train: 0.008048, test: 0.008252\n",
      " k = 6, RMSE on train: 0.007922, test: 0.008152\n",
      " k = 9, RMSE on train: 0.007883, test: 0.008126\n",
      " k = 12, RMSE on train: 0.007861, test: 0.008115\n",
      " k = 15, RMSE on train: 0.007848, test: 0.008109\n",
      " k = 18, RMSE on train: 0.007839, test: 0.008104\n",
      " k = 21, RMSE on train: 0.007832, test: 0.008102\n",
      " k = 24, RMSE on train: 0.007828, test: 0.008100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([0.008048315813386381,\n",
       "  0.007921563772777024,\n",
       "  0.007882540202367637,\n",
       "  0.007861034524445502,\n",
       "  0.007847796316826422,\n",
       "  0.007839334145523355,\n",
       "  0.007832462330618859,\n",
       "  0.007827652430881309],\n",
       " [0.008252076675815087,\n",
       "  0.00815189395065606,\n",
       "  0.008125620340576518,\n",
       "  0.008114690510848224,\n",
       "  0.008108643673803824,\n",
       "  0.008104293548197687,\n",
       "  0.008101767326184197,\n",
       "  0.008099632494657137])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def sparse_rmse(actual, test):\n",
    "    # Get the indices of the non-zero elements in actual\n",
    "    non_zero_indices = np.nonzero(actual)\n",
    "    \n",
    "    # Extract the corresponding values from actual and test\n",
    "    actual_non_zero = actual[non_zero_indices]\n",
    "    test_non_zero = test[non_zero_indices]\n",
    "    \n",
    "    # Compute the mean squared error of the non-zero elements in actual\n",
    "    mse = np.mean(np.square(actual_non_zero - np.where(actual_non_zero, test_non_zero, 0)))\n",
    "    \n",
    "    # Compute the root mean squared error\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "def user_based_collaborative_filtering(train_matrix,test_matrix, k_values):\n",
    "    # Convert the train and test sets to sparse matrices\n",
    "    learn_matrix, train_matrix= split_matrix(train_matrix,test_ratio=0.3)\n",
    "    train_sparse = csr_matrix(train_matrix)\n",
    "    test_sparse = csr_matrix(test_matrix)\n",
    "    learn_sparse = csr_matrix(learn_matrix)\n",
    "    # List to store the RMSE values for different k values for train and test sets\n",
    "    rmse_train = []\n",
    "    rmse_test = []\n",
    "\n",
    "    # Find the k most similar users for each user and predict the ratings for the train and test sets\n",
    "    for k in k_values:\n",
    "        knn_model = NearestNeighbors(n_neighbors=k+1, metric='cosine', algorithm='auto')\n",
    "        knn_model.fit(learn_sparse)\n",
    "        distances, indices = knn_model.kneighbors(learn_sparse, return_distance=True)\n",
    "        \n",
    "        # Predict the ratings for the train set\n",
    "        train_predictions = []\n",
    "        for i in range(train_matrix.shape[0]):\n",
    "            train_indices = train_sparse[i].nonzero()[1]\n",
    "            train_ratings = train_sparse[i, train_indices].toarray().squeeze()\n",
    "            similar_users = indices[i, 1:]\n",
    "            similarity_scores = distances[i, 1:]\n",
    "            neighbor_ratings = learn_sparse[similar_users][:, train_indices].toarray()\n",
    "            if neighbor_ratings.size > 0:\n",
    "                predicted_ratings = np.sum(neighbor_ratings * similarity_scores.reshape(-1, 1), axis=0) / np.sum(similarity_scores)\n",
    "            else:\n",
    "                predicted_ratings = np.zeros(len(train_indices))\n",
    "            train_predictions.append(predicted_ratings)\n",
    "        train_predictions = np.concatenate(train_predictions)\n",
    "        train_ratings = train_matrix[np.nonzero(train_matrix)]\n",
    "        rmse_train.append(sparse_rmse(train_ratings, train_predictions))\n",
    "\n",
    "        # Predict the ratings for the test set\n",
    "        test_predictions = []\n",
    "        for i in range(train_matrix.shape[0]):\n",
    "            test_indices = test_sparse[i].nonzero()[1]\n",
    "            test_ratings = test_sparse[i, test_indices].toarray().squeeze()\n",
    "            similar_users = indices[i, 1:]\n",
    "            similarity_scores = distances[i, 1:]\n",
    "            neighbor_ratings = train_sparse[similar_users][:, test_indices].toarray()\n",
    "            if neighbor_ratings.size > 0:\n",
    "                predicted_test_ratings = np.sum(neighbor_ratings * similarity_scores.reshape(-1, 1), axis=0) / np.sum(similarity_scores)\n",
    "            else:\n",
    "                predicted_test_ratings = np.zeros(len(test_indices))\n",
    "            test_predictions.append(predicted_test_ratings)\n",
    "        test_predictions = np.concatenate(test_predictions)\n",
    "        test_ratings = test_matrix[np.nonzero(test_matrix)]\n",
    "        rmse_test.append(sparse_rmse(test_ratings, test_predictions))\n",
    "        print('\\r k = %d, RMSE on train: %f, test: %f' % (k, rmse_train[-1], rmse_test[-1]))\n",
    "\n",
    "    # Plot the RMSE values for different k values for train and test sets\n",
    "    plt.plot(k_values, rmse_train, label='Train')\n",
    "    plt.plot(k_values, rmse_test, label='Test')\n",
    "    plt.xlabel('Number of nearest neighbors (k)')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return rmse_train, rmse_test\n",
    "user_based_collaborative_filtering(train_matrix, test_matrix, k_values=range(3,25,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_13900\\4002780050.py:44: RuntimeWarning: invalid value encountered in divide\n",
      "  predicted_ratings = np.sum(neighbor_ratings * similarity_scores.reshape(-1, 1), axis=0) / np.sum(similarity_scores)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_13900\\4002780050.py:61: RuntimeWarning: invalid value encountered in divide\n",
      "  predicted_test_ratings = np.sum(neighbor_ratings * similarity_scores.reshape(-1, 1), axis=0) / np.sum(similarity_scores)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " k = 3, RMSE on train: nan, test: nan\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.00 GiB for an array with shape (2081, 64467) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m user_based_collaborative_filtering(train_matrix\u001b[39m.\u001b[39;49mT, test_matrix\u001b[39m.\u001b[39;49mT, k_values\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m(\u001b[39m3\u001b[39;49m,\u001b[39m25\u001b[39;49m,\u001b[39m3\u001b[39;49m))\n",
      "Cell \u001b[1;32mIn[20], line 33\u001b[0m, in \u001b[0;36muser_based_collaborative_filtering\u001b[1;34m(train_matrix, test_matrix, k_values)\u001b[0m\n\u001b[0;32m     31\u001b[0m knn_model \u001b[39m=\u001b[39m NearestNeighbors(n_neighbors\u001b[39m=\u001b[39mk\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m'\u001b[39m, algorithm\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m knn_model\u001b[39m.\u001b[39mfit(learn_sparse)\n\u001b[1;32m---> 33\u001b[0m distances, indices \u001b[39m=\u001b[39m knn_model\u001b[39m.\u001b[39;49mkneighbors(learn_sparse, return_distance\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     35\u001b[0m \u001b[39m# Predict the ratings for the train set\u001b[39;00m\n\u001b[0;32m     36\u001b[0m train_predictions \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\sklearn\\neighbors\\_base.py:861\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 861\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m    862\u001b[0m         pairwise_distances_chunked(\n\u001b[0;32m    863\u001b[0m             X,\n\u001b[0;32m    864\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[0;32m    865\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[0;32m    866\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[0;32m    867\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    868\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    873\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1866\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[1;32m-> 1867\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39mmetric, n_jobs\u001b[39m=\u001b[39mn_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1868\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1869\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1871\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1873\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m   2037\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 2039\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1000\u001b[0m, in \u001b[0;36mcosine_distances\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \n\u001b[0;32m    976\u001b[0m \u001b[39mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[39mscipy.spatial.distance.cosine : Dense matrices only.\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[39m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[1;32m-> 1000\u001b[0m S \u001b[39m=\u001b[39m cosine_similarity(X, Y)\n\u001b[0;32m   1001\u001b[0m S \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1002\u001b[0m S \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1401\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1398\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1399\u001b[0m     Y_normalized \u001b[39m=\u001b[39m normalize(Y, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1401\u001b[0m K \u001b[39m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[39m.\u001b[39;49mT, dense_output\u001b[39m=\u001b[39;49mdense_output)\n\u001b[0;32m   1403\u001b[0m \u001b[39mreturn\u001b[39;00m K\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\sklearn\\utils\\extmath.py:197\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    189\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39m b\n\u001b[0;32m    191\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    192\u001b[0m     sparse\u001b[39m.\u001b[39missparse(a)\n\u001b[0;32m    193\u001b[0m     \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[0;32m    194\u001b[0m     \u001b[39mand\u001b[39;00m dense_output\n\u001b[0;32m    195\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    196\u001b[0m ):\n\u001b[1;32m--> 197\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39;49mtoarray()\n\u001b[0;32m    198\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m order \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap(\u001b[39m'\u001b[39m\u001b[39mcf\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_toarray_args(order, out)\n\u001b[0;32m   1052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mc_contiguous \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mOutput array must be C or F contiguous\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\setting app\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mzeros(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.00 GiB for an array with shape (2081, 64467) and data type float64"
     ]
    }
   ],
   "source": [
    "user_based_collaborative_filtering(train_matrix.T, test_matrix.T, k_values=range(3,25,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
